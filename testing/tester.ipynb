{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600758881258",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "str(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "\n",
    "# list_of_files = glob.glob('data/scrapped_data.csv') # * means all if need specific format then *.csv\n",
    "# latest_file = max(list_of_files, key=os.path.getctime)\n",
    "# print latest_file\n",
    "\n",
    "import os\n",
    "import platform\n",
    "\n",
    "def creation_date(path_to_file):\n",
    "\n",
    "    if platform.system() == 'Windows':\n",
    "        return os.path.getctime(path_to_file)\n",
    "    else:\n",
    "        stat = os.stat(path_to_file)\n",
    "        try:\n",
    "            return stat.st_birthtime\n",
    "        except AttributeError:\n",
    "            # We're probably on Linux. No easy way to get creation dates here,\n",
    "            # so we'll settle for when its content was last modified.\n",
    "            return stat.st_mtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1599973695\n"
    }
   ],
   "source": [
    "print(int(creation_date('data/scrapped_data.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os.path as osp\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(\n",
    "    \"data/scrapped_data.csv\",\n",
    "    f\"data/previous_data/scrapped_data_{creation_date('data/scrapped_data.csv')}.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_date(path_to_file):\n",
    "\n",
    "    if platform.system() == 'Windows':\n",
    "        return os.path.getctime(path_to_file)\n",
    "    else:\n",
    "        stat = os.stat(path_to_file)\n",
    "        try:\n",
    "            return stat.st_birthtime\n",
    "        except AttributeError:\n",
    "            # We're probably on Linux. No easy way to get creation dates here,\n",
    "            # so we'll settle for when its content was last modified.\n",
    "            return stat.st_mtime\n",
    "\n",
    "def move_data():\n",
    "    os.rename(\n",
    "    \"data/scrapped_data.csv\",\n",
    "    f\"data/previous_data/scrapped_data_{creation_date('data/scrapped_data.csv')}.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# Model saving\n",
    "import pickle\n",
    "\n",
    "# Math function needed for models\n",
    "from math import sqrt\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- NEW IMPORT ---\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(df, k = 10, target = 'category'): \n",
    "    # --- KFOLD & DATA ---\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits = k, shuffle = True, random_state = 42)\n",
    "    features = df[[col for col in df if col != target]]\n",
    "    target = df[target]   \n",
    "\n",
    "    # --- CREATING MODELS ---\n",
    "\n",
    "    def create_models():\n",
    "        models = list()\n",
    "\n",
    "        models.append(LogisticRegression(solver = 'lbfgs'))\n",
    "        models.append(KNeighborsClassifier(n_neighbors = 3)) # k = 5 by default\n",
    "        models.append(MultinomialNB())\n",
    "        models.append(RandomForestClassifier(max_depth=10, random_state=42))\n",
    "\n",
    "        return models\n",
    "\n",
    "    # --- CROSS_VALIDATION ---\n",
    "\n",
    "    def cv_eval_model(model, cv, X, y):\n",
    "\n",
    "        scoring = {\n",
    "            'R2': make_scorer(r2_score),\n",
    "            'MSE': make_scorer(mean_squared_error),\n",
    "            'MAE': make_scorer(mean_absolute_error),\n",
    "            'Accuracy': make_scorer(accuracy_score),\n",
    "            'Balanced_Acc': make_scorer(balanced_accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average = 'macro'),\n",
    "            'Recall': make_scorer(recall_score, average = 'macro'),\n",
    "            'F1': make_scorer(f1_score, average = 'macro'),\n",
    "        }\n",
    "\n",
    "        cross_val_obj = cross_validate(model, X, y, scoring = scoring, cv = cv, n_jobs = -1, return_estimator = True)  \n",
    "\n",
    "        return cross_val_obj # trained_model, \n",
    "\n",
    "    # --- RUNNING CROSS-VALIDATION ---\n",
    "\n",
    "    def run_cross_val(models, cv = kfold, X = features, y = target):\n",
    "        dict_df = dict()\n",
    "\n",
    "        for model in models:\n",
    "            cv_mean = cv_eval_model(model, cv, X, y) #trained_model, \n",
    "\n",
    "            # with open (type(model).__name__, 'wb') as f:\n",
    "            #     pickle.dump(model,f) \n",
    "\n",
    "            dict_df[type(model).__name__] = cv_mean\n",
    "\n",
    "        return dict_df\n",
    "\n",
    "    models_ = create_models()\n",
    "    dict_df = run_cross_val(models = models_)\n",
    "    return dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(df, k = 10, target = 'category'):\n",
    "    # --- KFOLD & DATA ---\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits = k, shuffle = True, random_state = 42)\n",
    "    features = df[[col for col in df if col != target]]\n",
    "    target = df[target]  \n",
    "\n",
    "    # --- CREATE MODELS ---\n",
    "\n",
    "    def create_models():\n",
    "        models = list()\n",
    "\n",
    "        models.append(LogisticRegression(solver = 'lbfgs'))\n",
    "        models.append(KNeighborsClassifier()) # k = 5 by default\n",
    "        models.append(MultinomialNB())\n",
    "        models.append(RandomForestClassifier(random_state=42))\n",
    "\n",
    "        return models\n",
    "\n",
    "    # --- SCORES ---\n",
    "\n",
    "    scoring = {\n",
    "    'R2': make_scorer(r2_score),\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Balanced_Acc': make_scorer(balanced_accuracy_score),\n",
    "    'Precision': make_scorer(precision_score, average = 'macro'),\n",
    "    'Recall': make_scorer(recall_score, average = 'macro'),\n",
    "    'F1': make_scorer(f1_score, average = 'macro'),\n",
    "    }\n",
    "\n",
    "    # --- PARAMETERS ---\n",
    "        # LR\n",
    "    Cs = [0.001, 0.01, 0.1, 0.3, 1, 3, 10, 100]\n",
    "\n",
    "        # KNN\n",
    "    n_neighbors_ = [3, 5, 8]\n",
    "        # MultiNB\n",
    "    alphas = [0, 0.5, 1.0]\n",
    "        # RandomForest\n",
    "    n_estimators_ = [50, 100, 150]\n",
    "    max_features_ = ['sqrt', 'log2']\n",
    "    ccp_alphas = [0, 0.5, 1]\n",
    "\n",
    "    dict_param_grid = {\n",
    "        'LogisticRegression': {'C': Cs},\n",
    "        'KNeighborsClassifier': {'n_neighbors': n_neighbors_},\n",
    "        'MultinomialNB': {'alpha': alphas},\n",
    "        'RandomForestClassifier': {'n_estimators': n_estimators_, 'max_features': max_features_, 'ccp_alpha': ccp_alphas}\n",
    "    }\n",
    "\n",
    "    # --- RUNNING GRIDSEARCHCV\n",
    "    models = create_models()\n",
    "\n",
    "    df_models = pd.DataFrame(columns = ['model_name', 'best_params', 'best_score', 'best_model'])\n",
    "\n",
    "    # --- PROGRESS BAR ---\n",
    "    my_bar = st.progress(0)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        param_grid = dict_param_grid[type(model).__name__]\n",
    "        grid_search = GridSearchCV(\n",
    "            model,\n",
    "            param_grid,\n",
    "            cv = kfold,\n",
    "            scoring = scoring,\n",
    "            refit = 'Accuracy',\n",
    "            n_jobs = -1\n",
    "        )\n",
    "        grid_search.fit(features, target)\n",
    "\n",
    "        df_input = pd.DataFrame({'model_name':f'{type(model).__name__}', 'best_params':grid_search.best_params_, 'best_score':grid_search.best_score_, 'best_model': grid_search.best_estimator_})\n",
    "        df_models = pd.concat([df_models,df_input], axis = 0, sort = False).reset_index(drop = True)\n",
    "\n",
    "        my_bar.progress((i+1)/len(models))\n",
    "\n",
    "    return df_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_under_sampling(df):\n",
    "\n",
    "    list_count = Counter(df['category']).most_common()\n",
    "    mid_num = int(((list_count[0][1]-list_count[9][1])/2))\n",
    "    mid_num = mid_num+list_count[9][1]\n",
    "    num_samples = mid_num\n",
    "    strategy = dict(Counter(df['category']))\n",
    "    \n",
    "    for i in range(len(strategy)):\n",
    "        if strategy[i] < num_samples:\n",
    "            strategy[i] = num_samples\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=strategy, random_state=42)\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    X = df.drop(['category'], axis=1)\n",
    "    y = df[['category']]\n",
    "\n",
    "    X_ros, y_ros = ros.fit_resample(X, y)\n",
    "    X_rous, y_rous = rus.fit_resample(X_ros, y_ros)\n",
    "    o_u_sample = X_rous.join(y_rous)\n",
    "\n",
    "    return o_u_sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tfidf(df, case_col = 'case', target_col = 'category'):\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    word_count_vectors = tfidf.fit_transform(df[case_col].values).todense().tolist()\n",
    "    \n",
    "    features = pd.DataFrame(\n",
    "    data = word_count_vectors,\n",
    "    columns = tfidf.get_feature_names()\n",
    "    )\n",
    "\n",
    "    df_ = features.merge(df[target_col], left_index=True, right_index= True)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_replacer(df, col = 'category', mul = True, main_cat = \"Deadbeats\"):\n",
    "\n",
    "    if mul == True: #--- MULTILABEL ---\n",
    "        dic_cat = {}\n",
    "        for i, cat in enumerate(list(df[col].unique())):\n",
    "            dic_cat[cat] = i\n",
    "\n",
    "    else: #--- CATEGORY VS. NOT CATEGORY ---\n",
    "        dic_cat = {\n",
    "            \"Deadbeats\" : 0,\n",
    "            'Dunces' : 0,\n",
    "            'Criminals' : 0,\n",
    "            'Racists' : 0,\n",
    "            'Homophobes' : 0,\n",
    "            'Sexist' : 0,\n",
    "            'Frenemies' : 0,\n",
    "            'Cryptic' : 0,\n",
    "            'Ingrates' : 0,\n",
    "            'Chaotic Good' : 0\n",
    "        }\n",
    "        \n",
    "        dic_cat[main_cat]  =  1\n",
    "\n",
    "    df[col].replace(to_replace = dic_cat, inplace = True)\n",
    "    \n",
    "    return df, dic_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_df = category_replacer(df_test)\n",
    "o_u_df = over_under_sampling(rep_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = convert_to_tfidf(o_u_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'LogisticRegression': {'fit_time': array([3.14393902, 2.8588872 , 3.09740496, 2.89498305, 3.10038233,\n         2.99936795, 3.17797208, 3.09765196, 1.95441699, 1.96075416]),\n  'score_time': array([0.18450785, 0.27821994, 0.24474216, 0.26767182, 0.24511385,\n         0.18505383, 0.18930578, 0.16417718, 0.08030701, 0.05656672]),\n  'estimator': (LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression(),\n   LogisticRegression()),\n  'test_R2': array([0.76262829, 0.48569463, 0.8595703 , 0.75888486, 0.71316819,\n         0.70273794, 0.88341685, 0.95230689, 0.93406341, 0.66504214]),\n  'test_MSE': array([1.95652174, 4.23913043, 1.15217391, 1.97826087, 2.39130435,\n         2.47826087, 0.95652174, 0.39130435, 0.54347826, 2.76086957]),\n  'test_MAE': array([0.47826087, 0.7173913 , 0.36956522, 0.5       , 0.52173913,\n         0.60869565, 0.26086957, 0.13043478, 0.15217391, 0.67391304]),\n  'test_Accuracy': array([0.86956522, 0.86956522, 0.82608696, 0.84782609, 0.86956522,\n         0.80434783, 0.89130435, 0.93478261, 0.95652174, 0.82608696]),\n  'test_Balanced_Acc': array([0.87 , 0.875, 0.825, 0.85 , 0.88 , 0.815, 0.895, 0.935, 0.95 ,\n         0.83 ]),\n  'test_Precision': array([0.86785714, 0.8975    , 0.79333333, 0.79714286, 0.89714286,\n         0.83952381, 0.91      , 0.94333333, 0.96666667, 0.83809524]),\n  'test_Recall': array([0.87 , 0.875, 0.825, 0.85 , 0.88 , 0.815, 0.895, 0.935, 0.95 ,\n         0.83 ]),\n  'test_F1': array([0.85811688, 0.86739927, 0.80380952, 0.81717172, 0.87944444,\n         0.81803752, 0.895     , 0.93535354, 0.95324675, 0.82550505])},\n 'KNeighborsClassifier': {'fit_time': array([0.60753679, 0.63515997, 0.63106203, 0.64617395, 0.48168206,\n         0.45103979, 0.73325419, 0.76797223, 0.75630593, 0.59619403]),\n  'score_time': array([0.50019503, 1.06670618, 0.4732101 , 0.85075593, 0.55711579,\n         0.72244215, 0.63362169, 0.62444687, 0.53143501, 0.34826994]),\n  'estimator': (KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3),\n   KNeighborsClassifier(n_neighbors=3)),\n  'test_R2': array([0.70724156, 0.37492116, 0.70589252, 0.59725822, 0.17079531,\n         0.23598435, 0.04083866, 0.36144231, 0.52261912, 0.27206009]),\n  'test_MSE': array([2.41304348, 5.15217391, 2.41304348, 3.30434783, 6.91304348,\n         6.36956522, 7.86956522, 5.23913043, 3.93478261, 6.        ]),\n  'test_MAE': array([0.5       , 1.19565217, 0.7173913 , 0.91304348, 1.43478261,\n         1.2826087 , 1.47826087, 1.02173913, 0.97826087, 1.17391304]),\n  'test_Accuracy': array([0.84782609, 0.67391304, 0.73913043, 0.69565217, 0.60869565,\n         0.65217391, 0.63043478, 0.69565217, 0.7173913 , 0.7173913 ]),\n  'test_Balanced_Acc': array([0.84 , 0.665, 0.72 , 0.675, 0.625, 0.67 , 0.64 , 0.7  , 0.72 ,\n         0.725]),\n  'test_Precision': array([0.87047619, 0.66825397, 0.70583333, 0.70833333, 0.53795455,\n         0.65952381, 0.6025    , 0.72583333, 0.68378788, 0.69888889]),\n  'test_Recall': array([0.84 , 0.665, 0.72 , 0.675, 0.625, 0.67 , 0.64 , 0.7  , 0.72 ,\n         0.725]),\n  'test_F1': array([0.82438672, 0.62418803, 0.69838772, 0.62887612, 0.5625    ,\n         0.61584416, 0.59853924, 0.68049728, 0.68450577, 0.69065657])},\n 'MultinomialNB': {'fit_time': array([0.31006479, 0.29060817, 0.26216817, 0.23723507, 0.23837018,\n         0.22489595, 0.22013903, 0.18348622, 0.19997191, 0.19569516]),\n  'score_time': array([0.15987611, 0.21673918, 0.15124488, 0.26796889, 0.25532269,\n         0.19636416, 0.24929214, 0.23551679, 0.06686521, 0.07490087]),\n  'estimator': (MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB(),\n   MultinomialNB()),\n  'test_R2': array([0.82328995, 0.22194828, 0.58665975, 0.81717643, 0.3559322 ,\n         0.47848761, 0.71119175, 0.65819941, 0.73625366, 0.39865833]),\n  'test_MSE': array([1.45652174, 6.41304348, 3.39130435, 1.5       , 5.36956522,\n         4.34782609, 2.36956522, 2.80434783, 2.17391304, 4.95652174]),\n  'test_MAE': array([0.45652174, 1.10869565, 0.73913043, 0.5       , 1.06521739,\n         1.        , 0.63043478, 0.7173913 , 0.56521739, 1.        ]),\n  'test_Accuracy': array([0.82608696, 0.76086957, 0.7826087 , 0.80434783, 0.69565217,\n         0.65217391, 0.7826087 , 0.73913043, 0.82608696, 0.73913043]),\n  'test_Balanced_Acc': array([0.82 , 0.76 , 0.775, 0.8  , 0.72 , 0.675, 0.785, 0.74 , 0.825,\n         0.74 ]),\n  'test_Precision': array([0.83916667, 0.84746032, 0.77380952, 0.7452381 , 0.63142857,\n         0.62083333, 0.82642857, 0.73555556, 0.86285714, 0.72603175]),\n  'test_Recall': array([0.82 , 0.76 , 0.775, 0.8  , 0.72 , 0.675, 0.785, 0.74 , 0.825,\n         0.74 ]),\n  'test_F1': array([0.7984238 , 0.73109668, 0.72787879, 0.75272727, 0.64269841,\n         0.60048368, 0.76257631, 0.69382562, 0.8       , 0.67746032])},\n 'RandomForestClassifier': {'fit_time': array([1.76917291, 1.97421885, 1.95012188, 1.79959893, 2.33222413,\n         2.39327693, 2.28898096, 2.38576889, 0.89109993, 0.86245084]),\n  'score_time': array([0.26248312, 0.32031322, 0.33164525, 0.30964303, 0.40524793,\n         0.40661931, 0.29493189, 0.39522004, 0.12541604, 0.11040902]),\n  'estimator': (RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42),\n   RandomForestClassifier(max_depth=10, random_state=42)),\n  'test_R2': array([0.6966917 , 0.65185482, 0.54426588, 0.58136052, 0.59843546,\n         0.4654498 , 0.59990784, 0.60255746, 0.65976722, 0.78900292]),\n  'test_MSE': array([2.5       , 2.86956522, 3.73913043, 3.43478261, 3.34782609,\n         4.45652174, 3.2826087 , 3.26086957, 2.80434783, 1.73913043]),\n  'test_MAE': array([0.58695652, 0.65217391, 0.7826087 , 0.82608696, 0.73913043,\n         0.93478261, 0.80434783, 0.65217391, 0.67391304, 0.47826087]),\n  'test_Accuracy': array([0.84782609, 0.84782609, 0.7826087 , 0.76086957, 0.80434783,\n         0.7173913 , 0.76086957, 0.80434783, 0.7826087 , 0.82608696]),\n  'test_Balanced_Acc': array([0.845, 0.845, 0.775, 0.745, 0.815, 0.735, 0.765, 0.81 , 0.78 ,\n         0.83 ]),\n  'test_Precision': array([0.82380952, 0.86333333, 0.74      , 0.75833333, 0.82666667,\n         0.71666667, 0.77833333, 0.76666667, 0.81944444, 0.855     ]),\n  'test_Recall': array([0.845, 0.845, 0.775, 0.745, 0.815, 0.735, 0.765, 0.81 , 0.78 ,\n         0.83 ]),\n  'test_F1': array([0.82077922, 0.83238095, 0.75555556, 0.73114719, 0.81359307,\n         0.72      , 0.76489899, 0.78133644, 0.76244589, 0.83439394])}}"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "kfold_cross_validation(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   fit_time  score_time             estimator   test_R2  test_MSE  test_MAE  \\\n0  3.943365    0.344837  LogisticRegression()  0.762628  1.956522  0.478261   \n1  4.003656    0.301153  LogisticRegression()  0.485695  4.239130  0.717391   \n2  4.248466    0.204503  LogisticRegression()  0.859570  1.152174  0.369565   \n3  4.208723    0.167869  LogisticRegression()  0.758885  1.978261  0.500000   \n4  4.026634    0.262611  LogisticRegression()  0.713168  2.391304  0.521739   \n5  3.948291    0.221415  LogisticRegression()  0.702738  2.478261  0.608696   \n6  3.933197    0.225026  LogisticRegression()  0.883417  0.956522  0.260870   \n7  3.971508    0.262017  LogisticRegression()  0.952307  0.391304  0.130435   \n8  2.146743    0.113792  LogisticRegression()  0.934063  0.543478  0.152174   \n9  2.114204    0.094597  LogisticRegression()  0.665042  2.760870  0.673913   \n\n   test_Accuracy  test_Balanced_Acc  test_Precision  test_Recall   test_F1  \n0       0.869565              0.870        0.867857        0.870  0.858117  \n1       0.869565              0.875        0.897500        0.875  0.867399  \n2       0.826087              0.825        0.793333        0.825  0.803810  \n3       0.847826              0.850        0.797143        0.850  0.817172  \n4       0.869565              0.880        0.897143        0.880  0.879444  \n5       0.804348              0.815        0.839524        0.815  0.818038  \n6       0.891304              0.895        0.910000        0.895  0.895000  \n7       0.934783              0.935        0.943333        0.935  0.935354  \n8       0.956522              0.950        0.966667        0.950  0.953247  \n9       0.826087              0.830        0.838095        0.830  0.825505  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>estimator</th>\n      <th>test_R2</th>\n      <th>test_MSE</th>\n      <th>test_MAE</th>\n      <th>test_Accuracy</th>\n      <th>test_Balanced_Acc</th>\n      <th>test_Precision</th>\n      <th>test_Recall</th>\n      <th>test_F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.943365</td>\n      <td>0.344837</td>\n      <td>LogisticRegression()</td>\n      <td>0.762628</td>\n      <td>1.956522</td>\n      <td>0.478261</td>\n      <td>0.869565</td>\n      <td>0.870</td>\n      <td>0.867857</td>\n      <td>0.870</td>\n      <td>0.858117</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.003656</td>\n      <td>0.301153</td>\n      <td>LogisticRegression()</td>\n      <td>0.485695</td>\n      <td>4.239130</td>\n      <td>0.717391</td>\n      <td>0.869565</td>\n      <td>0.875</td>\n      <td>0.897500</td>\n      <td>0.875</td>\n      <td>0.867399</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.248466</td>\n      <td>0.204503</td>\n      <td>LogisticRegression()</td>\n      <td>0.859570</td>\n      <td>1.152174</td>\n      <td>0.369565</td>\n      <td>0.826087</td>\n      <td>0.825</td>\n      <td>0.793333</td>\n      <td>0.825</td>\n      <td>0.803810</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.208723</td>\n      <td>0.167869</td>\n      <td>LogisticRegression()</td>\n      <td>0.758885</td>\n      <td>1.978261</td>\n      <td>0.500000</td>\n      <td>0.847826</td>\n      <td>0.850</td>\n      <td>0.797143</td>\n      <td>0.850</td>\n      <td>0.817172</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.026634</td>\n      <td>0.262611</td>\n      <td>LogisticRegression()</td>\n      <td>0.713168</td>\n      <td>2.391304</td>\n      <td>0.521739</td>\n      <td>0.869565</td>\n      <td>0.880</td>\n      <td>0.897143</td>\n      <td>0.880</td>\n      <td>0.879444</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.948291</td>\n      <td>0.221415</td>\n      <td>LogisticRegression()</td>\n      <td>0.702738</td>\n      <td>2.478261</td>\n      <td>0.608696</td>\n      <td>0.804348</td>\n      <td>0.815</td>\n      <td>0.839524</td>\n      <td>0.815</td>\n      <td>0.818038</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.933197</td>\n      <td>0.225026</td>\n      <td>LogisticRegression()</td>\n      <td>0.883417</td>\n      <td>0.956522</td>\n      <td>0.260870</td>\n      <td>0.891304</td>\n      <td>0.895</td>\n      <td>0.910000</td>\n      <td>0.895</td>\n      <td>0.895000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3.971508</td>\n      <td>0.262017</td>\n      <td>LogisticRegression()</td>\n      <td>0.952307</td>\n      <td>0.391304</td>\n      <td>0.130435</td>\n      <td>0.934783</td>\n      <td>0.935</td>\n      <td>0.943333</td>\n      <td>0.935</td>\n      <td>0.935354</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2.146743</td>\n      <td>0.113792</td>\n      <td>LogisticRegression()</td>\n      <td>0.934063</td>\n      <td>0.543478</td>\n      <td>0.152174</td>\n      <td>0.956522</td>\n      <td>0.950</td>\n      <td>0.966667</td>\n      <td>0.950</td>\n      <td>0.953247</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.114204</td>\n      <td>0.094597</td>\n      <td>LogisticRegression()</td>\n      <td>0.665042</td>\n      <td>2.760870</td>\n      <td>0.673913</td>\n      <td>0.826087</td>\n      <td>0.830</td>\n      <td>0.838095</td>\n      <td>0.830</td>\n      <td>0.825505</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "pd.DataFrame(kfold_cross_validation(final_df)['LogisticRegression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-51042dda7a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-2eced2925b79>\u001b[0m in \u001b[0;36mbest_model\u001b[0;34m(df, k, target)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdf_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34mf'{type(model).__name__}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_params'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_score'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mdf_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                     \u001b[0;34m\"Mixing dicts with non-Series may lead to ambiguous ordering.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "best_model(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "key    A    B\n0  K0   A0  NaN\n1  K1   A1  NaN\n2  K2   A2  NaN\n3  K3   A3  NaN\n4  K4   A4  NaN\n5  K5   A5  NaN\n6  K0  NaN   B0\n7  K1  NaN   B1\n8  K2  NaN   B2\n9   a  NaN    b\n"
    }
   ],
   "source": [
    "df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
    "                   'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
    "\n",
    "\n",
    "other = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'a'],\n",
    "                      'B': ['B0', 'B1', 'B2', 'b']})\n",
    "\n",
    "print(pd.concat([df,other], axis = 0, sort = False).reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}